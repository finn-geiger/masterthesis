{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning for Classification and Regression Tree (RF) classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing described parameter settings for RF algorithm using Google Earth Engine Python API and NICFI Normalized Analytic Basemap from December 2022\n",
    "\n",
    "Author: Finn Geiger\\\n",
    "Date: March 30th 2023\\\n",
    "Contact:\n",
    "- https://github.com/finn-geiger\n",
    "- https://www.linkedin.com/in/finn-geiger-b1329a20b/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Import and setup\n",
    "#### 1.1 Importing the required libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geemap\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "#%pip install tabulate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following classes and landcover IDs will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤════════════════╕\n",
      "│ Class name   │   landcover ID │\n",
      "╞══════════════╪════════════════╡\n",
      "│ Informal     │              1 │\n",
      "├──────────────┼────────────────┤\n",
      "│ Formal       │              2 │\n",
      "├──────────────┼────────────────┤\n",
      "│ Industrial   │              3 │\n",
      "├──────────────┼────────────────┤\n",
      "│ Roads        │              4 │\n",
      "├──────────────┼────────────────┤\n",
      "│ Vacant land  │              5 │\n",
      "├──────────────┼────────────────┤\n",
      "│ Vegetation   │              6 │\n",
      "├──────────────┼────────────────┤\n",
      "│ Water-bodies │              7 │\n",
      "╘══════════════╧════════════════╛\n"
     ]
    }
   ],
   "source": [
    "info = {'Class name': ['Informal', 'Formal', 'Industrial', 'Roads', 'Vacant land', 'Vegetation', 'Water-bodies'],\n",
    "        'landcover ID': [1, 2, 3, 4, 5, 6, 7]}\n",
    "\n",
    "print(tabulate(info, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### When first using the GEE Python API the user must authenticate and initialize the environment by using the following two lines of codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ee.Authenticate() \n",
    "#ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16535236141f408a9c118cb7b016291e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating the map\n",
    "Map = geemap.Map()\n",
    "\n",
    "# loading the interactive map\n",
    "Map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Importing the datasets from GEE assets and data catalog and clipping the basemap to the AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Base scene\n",
    "nicfi = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa')\n",
    "\n",
    "# Filter basemaps by date and get the first image from filtered results\n",
    "basemap_2022_12 = nicfi.filter(ee.Filter.date('2022-12-01','2023-01-01')).first()\n",
    "\n",
    "# Visualizing the scene\n",
    "vis_params = {\"bands\":[\"R\",\"G\",\"B\"],\"min\":64,\"max\":5454,\"gamma\":1.8}\n",
    "\n",
    "# Adding the basemap to the map\n",
    "Map.centerObject(basemap_2022_12, 4)\n",
    "Map.addLayer(basemap_2022_12, vis_params, '2022-12 mosaic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the AOI and Masking the base scene\n",
    "vis_params_aoi = {'color': 'blue'}\n",
    "aoi_windhoek = ee.FeatureCollection('users/s85315/masterthesis/Study_Area_Windhoek')\n",
    "\n",
    "# Adding the AOI to the map\n",
    "Map.addLayer(aoi_windhoek, vis_params_aoi, 'AOI')\n",
    "Map.centerObject(aoi_windhoek, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping the basescene to the AOI\n",
    "basescene = basemap_2022_12.clipToCollection(aoi_windhoek)\n",
    "Map.addLayer(basescene, vis_params, 'clipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing training data samples and adding them to the map\n",
    "# Transforming the Geometries into FeatureCollections and applying properties\n",
    "TS_Informal_Points = ee.FeatureCollection('users/s85315/masterthesis/TrainingSamples/TS_Informal_RPoints')\n",
    "TS_Formal_Points = ee.FeatureCollection('users/s85315/masterthesis/TrainingSamples/TS_Formal_RPoints')\n",
    "TS_Industrial_Points = ee.FeatureCollection('users/s85315/masterthesis/TrainingSamples/TS_Industrial_RPoints')\n",
    "TS_Roads_Points = ee.FeatureCollection('users/s85315/masterthesis/TrainingSamples/TS_Roads_RPoints')\n",
    "TS_VacantLand_Points = ee.FeatureCollection('users/s85315/masterthesis/TrainingSamples/TS_VacantLand_RPoints')\n",
    "TS_Vegetation_Points = ee.FeatureCollection('users/s85315/masterthesis/TrainingSamples/TS_Vegetation_RPoints')\n",
    "TS_Waterbodies_Points = ee.FeatureCollection('users/s85315/masterthesis/TrainingSamples/TS_Waterbodies_RPoints')\n",
    "\n",
    "# adding the samples to the map\n",
    "# Map.addLayer(TS_Informal_Points, {'color': 'c43c39'}, 'Informal Training Data', False)\n",
    "# Map.addLayer(TS_Formal_Points, {'color': 'e5b636'}, 'Formal Training Data', False)\n",
    "# Map.addLayer(TS_Industrial_Points, {'color': '2f2f2f'}, 'Industrial Training Data', False)\n",
    "# Map.addLayer(TS_Roads_Points, {'color': 'aaaaaa'}, 'Roads Training Data', False)\n",
    "# Map.addLayer(TS_VacantLand_Points, {'color': 'b08e7a'}, 'Vacant land Training Data', False)\n",
    "# Map.addLayer(TS_Vegetation_Points, {'color': '85b66f'}, 'Vegetation Training Data', False)\n",
    "# Map.addLayer(TS_Waterbodies_Points, {'color': 'a5bfdd'}, 'Waterbodies Training Data', False)\n",
    "\n",
    "# merging all FeatureCollections into one layer\n",
    "training_samples = TS_Informal_Points.merge(TS_Formal_Points).merge(TS_Industrial_Points).merge(TS_Roads_Points).merge(TS_VacantLand_Points).merge(TS_Vegetation_Points).merge(TS_Waterbodies_Points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Classification with RF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Applying training samples on the base scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the training samples to the basescene\n",
    "training = basescene.sampleRegions(**{\n",
    "    'collection': training_samples, \n",
    "    'properties': ['landcover'], \n",
    "    'scale': 4.77\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Configuration and creation of the empty RF classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating variable for parameter settings\n",
    "# Mtry will be set to default\n",
    "# Ntree values between [50:550] will be tested using a step size of 50\n",
    "RF_param = 550\n",
    "max_nodes_from_pt_cart = 40\n",
    "classifier_params = {\n",
    "              'numberOfTrees':RF_param, # \tNtree; The number of decision trees to create.\n",
    "              'variablesPerSplit':None, # Mtry; The number of variables per split. If unspecified, uses the square root of the number of variables.\n",
    "              'minLeafPopulation':1, # smallest sample size possible per leaf\n",
    "              'bagFraction':0.5, #The fraction of input to bag per tree.\n",
    "              'maxNodes':None, # the number of individual decision tree models\n",
    "              #'maxNodes':max_nodes_from_pt_cart, # the number of individual decision tree models\n",
    "              'seed': 0}  # The randomization seed.\n",
    "\n",
    "\n",
    "# creating the classifier using RF\n",
    "classifier = ee.Classifier.smileRandomForest(**classifier_params).train(**{\n",
    "  'features': training,  \n",
    "  'classProperty': 'landcover', \n",
    "  'inputProperties': basescene.bandNames()\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 classifying the basescene and visualizing the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the basescene using the created classifier\n",
    "classified_basescene = basescene.classify(classifier)\n",
    "\n",
    "# creating the visualization parameters\n",
    "palette = ['c43c39', 'e5b636', '2f2f2f', 'aaaaaa', 'b08e7a', '85b66f', 'a5bfdd']\n",
    "vis_params_classified = {'min': 1, 'max': 7, 'palette': palette}\n",
    "\n",
    "\n",
    "Map.addLayer(classified_basescene, vis_params_classified, 'classified basescene')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Exporting the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.1 Exporting to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the FeatureCollection to Geometry for export\n",
    "aoi_geom = aoi_windhoek.geometry()\n",
    "\n",
    "# exporting to Google drive with GEE API\n",
    "# export = ee.batch.Export.image.toDrive(**{\n",
    "#     'image': classified_basescene,\n",
    "#     'description': 'classified_map', # TODO: change name here\n",
    "#     'folder': 'data', # TODO: change name here\n",
    "#     'scale': 4.77,\n",
    "#     'region': aoi_geom\n",
    "# })\n",
    "\n",
    "# # starting the process\n",
    "# export.start()\n",
    "\n",
    "# # tracking the process\n",
    "# while export.active():\n",
    "#   print('Polling for task (id: {}).'.format(export.id))\n",
    "#   time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.2 Exporting to Asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting to Google Asset\n",
    "# export = ee.batch.Export.image.toAsset(**{\n",
    "#   'image': classified_basescene,\n",
    "#   'description': 'Export classified map',\n",
    "#   'assetId': 'users/s85315/masterthesis/Testing/export_basescene', # TODO: change name here\n",
    "#   'scale': 100,\n",
    "#   'region': aoi_geom\n",
    "# })\n",
    "\n",
    "# # starting the process\n",
    "# export.start()\n",
    "\n",
    "# # tracking the process\n",
    "# while export.active():\n",
    "#   print('Polling for task (id: {}).'.format(export.id))\n",
    "#   time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Accuracy assessment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Importing validation samples from GEE Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Geometries into FeatureCollections and applying properties\n",
    "VS_Informal_Points = ee.FeatureCollection('users/s85315/masterthesis/ValidationSamples/VS_Informal_RPoints')\n",
    "VS_Formal_Points = ee.FeatureCollection('users/s85315/masterthesis/ValidationSamples/VS_Formal_RPoints')\n",
    "VS_Industrial_Points = ee.FeatureCollection('users/s85315/masterthesis/ValidationSamples/VS_Industrial_RPoints')\n",
    "VS_Roads_Points = ee.FeatureCollection('users/s85315/masterthesis/ValidationSamples/VS_Roads_RPoints')\n",
    "VS_VacantLand_Points = ee.FeatureCollection('users/s85315/masterthesis/ValidationSamples/VS_VacantLand_RPoints')\n",
    "VS_Vegetation_Points = ee.FeatureCollection('users/s85315/masterthesis/ValidationSamples/VS_Vegetation_RPoints')\n",
    "VS_Waterbodies_Points = ee.FeatureCollection('users/s85315/masterthesis/ValidationSamples/VS_Waterbodies_RPoints')\n",
    "\n",
    "validation_samples = VS_Informal_Points.merge(VS_Formal_Points).merge(VS_Industrial_Points).merge(VS_Roads_Points).merge(VS_VacantLand_Points).merge(VS_Vegetation_Points).merge(VS_Waterbodies_Points)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Applying the validation samples to the basescene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the validation samples to the classified map\n",
    "validation = classified_basescene.sampleRegions(**{\n",
    "  'collection': validation_samples,\n",
    "  'properties': ['landcover'],\n",
    "  'tileScale': 16,\n",
    "  'scale': 4.77,\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Generating the error matrix and printing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[0, 0, 0, 0, 0, 0, 0, 0], [0, 18, 6, 1, 4, 1, 0, 0], [0, 2, 25, 2, 1, 0, 0, 0], [0, 4, 8, 15, 3, 0, 0, 0], [0, 1, 1, 1, 26, 1, 0, 0], [0, 3, 0, 1, 2, 23, 1, 0], [0, 0, 0, 0, 0, 0, 25, 5], [0, 0, 0, 0, 0, 0, 1, 29]]\n",
      "Overall Accuracy 0.7666666666666667\n",
      "Producers Accuracy [[0], [0.6], [0.8333333333333334], [0.5], [0.8666666666666667], [0.7666666666666667], [0.8333333333333334], [0.9666666666666667]]\n",
      "Consumers Accuracy [[0, 0.6428571428571429, 0.625, 0.75, 0.7222222222222222, 0.92, 0.9259259259259259, 0.8529411764705882]]\n",
      "Kappa 0.7277777777777777\n"
     ]
    }
   ],
   "source": [
    "basescene_error_matrix = validation.errorMatrix('landcover', 'classification')\n",
    "\n",
    "# printing statistics\n",
    "print('Confusion Matrix', basescene_error_matrix.getInfo())\n",
    "print('Overall Accuracy', basescene_error_matrix.accuracy().getInfo())\n",
    "print('Producers Accuracy', basescene_error_matrix.producersAccuracy().getInfo())\n",
    "print('Consumers Accuracy', basescene_error_matrix.consumersAccuracy().getInfo())\n",
    "print('Kappa', basescene_error_matrix.kappa().getInfo())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1 Visualizing the error matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤════════════╤══════════╤══════════════╤═════════╤═══════════════╤══════════════╤════════════════╤═════════╕\n",
      "│              │   Informal │   Formal │   Industrial │   Roads │   Vacant land │   Vegetation │   Water-bodies │   Total │\n",
      "╞══════════════╪════════════╪══════════╪══════════════╪═════════╪═══════════════╪══════════════╪════════════════╪═════════╡\n",
      "│ Informal     │         18 │        6 │            1 │       4 │             1 │            0 │              0 │      30 │\n",
      "├──────────────┼────────────┼──────────┼──────────────┼─────────┼───────────────┼──────────────┼────────────────┼─────────┤\n",
      "│ Formal       │          2 │       25 │            2 │       1 │             0 │            0 │              0 │      30 │\n",
      "├──────────────┼────────────┼──────────┼──────────────┼─────────┼───────────────┼──────────────┼────────────────┼─────────┤\n",
      "│ Industrial   │          4 │        8 │           15 │       3 │             0 │            0 │              0 │      30 │\n",
      "├──────────────┼────────────┼──────────┼──────────────┼─────────┼───────────────┼──────────────┼────────────────┼─────────┤\n",
      "│ Roads        │          1 │        1 │            1 │      26 │             1 │            0 │              0 │      30 │\n",
      "├──────────────┼────────────┼──────────┼──────────────┼─────────┼───────────────┼──────────────┼────────────────┼─────────┤\n",
      "│ Vacant land  │          3 │        0 │            1 │       2 │            23 │            1 │              0 │      30 │\n",
      "├──────────────┼────────────┼──────────┼──────────────┼─────────┼───────────────┼──────────────┼────────────────┼─────────┤\n",
      "│ Vegetation   │          0 │        0 │            0 │       0 │             0 │           25 │              5 │      30 │\n",
      "├──────────────┼────────────┼──────────┼──────────────┼─────────┼───────────────┼──────────────┼────────────────┼─────────┤\n",
      "│ Water-bodies │          0 │        0 │            0 │       0 │             0 │            1 │             29 │      30 │\n",
      "├──────────────┼────────────┼──────────┼──────────────┼─────────┼───────────────┼──────────────┼────────────────┼─────────┤\n",
      "│ Total        │         28 │       40 │           20 │      36 │            25 │           27 │             34 │     210 │\n",
      "╘══════════════╧════════════╧══════════╧══════════════╧═════════╧═══════════════╧══════════════╧════════════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "# creating a Pandas Dataframe for the error matrix\n",
    "error_matrix = basescene_error_matrix.getInfo()\n",
    "df_error_matrix = pd.DataFrame(error_matrix)\n",
    "\n",
    "# deleting the first row and column since GEE add's a class with the landcover ID 0 by default.\n",
    "df_error_matrix.columns = ['not used','Informal', 'Formal', 'Industrial', 'Roads', 'Vacant land', 'Vegetation', 'Water-bodies']\n",
    "df_error_matrix = df_error_matrix.drop(df_error_matrix.columns[0],axis=1)\n",
    "df_error_matrix.drop(index=df_error_matrix.index[0], axis=0, inplace=True)\n",
    "\n",
    "# calculating row and column sum of points\n",
    "column_total = df_error_matrix.sum()\n",
    "column_total.name = 'Total'\n",
    "df_error_matrix.loc[8] = column_total\n",
    "df_error_matrix['Total'] = df_error_matrix.sum(axis=1)\n",
    "\n",
    "header_error_matrix = ['Informal', 'Formal', 'Industrial', 'Roads', 'Vacant land', 'Vegetation', 'Water-bodies', 'Total']\n",
    "df_error_matrix['Names'] = header_error_matrix\n",
    "df_error_matrix = df_error_matrix.set_index('Names')\n",
    "\n",
    "\n",
    "print(tabulate(df_error_matrix, headers=header_error_matrix, tablefmt='fancy_grid', showindex=header_error_matrix))\n",
    "#df_error_matrix.to_csv(f\"./accuracies/RF/RF_Error_Matrix_{RF_param}.csv\", sep=';', index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2 Producer's and consumer's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════════════╤══════════════╕\n",
      "│   Producer's Accuracy [%] │ Class name   │\n",
      "╞═══════════════════════════╪══════════════╡\n",
      "│                     60    │ Informal     │\n",
      "├───────────────────────────┼──────────────┤\n",
      "│                     83.33 │ Formal       │\n",
      "├───────────────────────────┼──────────────┤\n",
      "│                     50    │ Industrial   │\n",
      "├───────────────────────────┼──────────────┤\n",
      "│                     86.67 │ Roads        │\n",
      "├───────────────────────────┼──────────────┤\n",
      "│                     76.67 │ Vacant land  │\n",
      "├───────────────────────────┼──────────────┤\n",
      "│                     83.33 │ Vegetation   │\n",
      "├───────────────────────────┼──────────────┤\n",
      "│                     96.67 │ Water-bodies │\n",
      "╘═══════════════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# creating the lists \n",
    "producers = basescene_error_matrix.producersAccuracy().getInfo()\n",
    "df_producers = pd.DataFrame(producers)\n",
    "df_producers.drop(index=df_producers.index[0], axis=0, inplace=True)\n",
    "\n",
    "class_names = ['Informal', 'Formal', 'Industrial', 'Roads', 'Vacant land', 'Vegetation', 'Water-bodies']\n",
    "df_producers['class names'] = class_names\n",
    "df_producers.columns = [\"Producer Accuracy\", \"Class name\"]\n",
    "df_producers['Producer Accuracy'] = df_producers['Producer Accuracy'].multiply(100).round(2)\n",
    "\n",
    "\n",
    "print(tabulate(df_producers, headers=[\"Producer's Accuracy [%]\", \"Class name\"], tablefmt='fancy_grid',  showindex=False))\n",
    "#df_producers.to_csv(f\"./accuracies/RF/RF_Producers_Accuracy_{RF_param}.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════════════╤══════════════╕\n",
      "│   Consumers's Accuracy [%] │ Class name   │\n",
      "╞════════════════════════════╪══════════════╡\n",
      "│                      64.29 │ Informal     │\n",
      "├────────────────────────────┼──────────────┤\n",
      "│                      62.5  │ Formal       │\n",
      "├────────────────────────────┼──────────────┤\n",
      "│                      75    │ Industrial   │\n",
      "├────────────────────────────┼──────────────┤\n",
      "│                      72.22 │ Roads        │\n",
      "├────────────────────────────┼──────────────┤\n",
      "│                      92    │ Vacant land  │\n",
      "├────────────────────────────┼──────────────┤\n",
      "│                      92.59 │ Vegetation   │\n",
      "├────────────────────────────┼──────────────┤\n",
      "│                      85.29 │ Water-bodies │\n",
      "╘════════════════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# creating a dataframe from the list of consumer accuracies and remove landcover ID 0\n",
    "consumers = basescene_error_matrix.consumersAccuracy().getInfo()\n",
    "df_consumers = pd.DataFrame(consumers)\n",
    "df_consumers = df_consumers.drop(df_consumers.columns[0],axis=1)\n",
    "df_consumers.columns = class_names\n",
    "\n",
    "# reshaping the dataframe from wide to long format:\n",
    "df_consumers_long = pd.melt(df_consumers, var_name='Class name', value_name=\"Consumer Accuracy\")\n",
    "df_consumers_long = df_consumers_long[['Consumer Accuracy', 'Class name']]\n",
    "df_consumers_long['Consumer Accuracy'] = df_consumers_long['Consumer Accuracy'].multiply(100).round(2)\n",
    "\n",
    "\n",
    "print(tabulate(df_consumers_long, headers=[\"Consumers's Accuracy [%]\", \"Class name\"], tablefmt='fancy_grid',  showindex=False))\n",
    "#df_consumers_long.to_csv(f\"./accuracies/RF/RF_Consumers_Accuracy_{RF_param}.csv\", sep=';', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3 Overall Accuracy and Kappa Coefficent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOverall Accuracy 76.67 %\u001b[0m\n",
      "\u001b[1mKappa coefficent 0.73\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# defining the variables\n",
    "overall_accuracy = basescene_error_matrix.accuracy().getInfo()\n",
    "overall_print = str(round(overall_accuracy * 100, 2))\n",
    "kappa = basescene_error_matrix.kappa().getInfo()\n",
    "\n",
    "df_overall_kappa = pd.DataFrame()\n",
    "\n",
    "# printing out vaLues\n",
    "print(\"\\033[1m\" + \"Overall Accuracy \" + overall_print + \" %\" + \"\\033[0m\")\n",
    "print(\"\\033[1m\" + \"Kappa coefficent \" + str(round(kappa, 2)) + \"\\033[0m\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resources for code snippets\n",
    "\n",
    "https://colab.research.google.com/github/csaybar/EEwPython/blob/dev/10_Export.ipynb \\\n",
    "https://worldbank.github.io/OpenNightLights/tutorials/mod6_6_RF_classifier.html \\\n",
    "https://towardsdatascience.com/how-to-easily-create-tables-in-python-2eaea447d8fd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
